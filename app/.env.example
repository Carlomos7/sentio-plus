# --- App ---
DEBUG_MODE=false

# --- LLM Provider ---
# Options: openai | bedrock
# "openai" works with any OpenAI-compatible API (Ollama, LM Studio, vLLM, OpenAI)
# LLM_PROVIDER=openai
LLM_MODEL=anthropic.claude-3-sonnet-20240229-v1:0
# LLM_BASE_URL=http://localhost:1234/v1

# --- AWS (only if LLM_PROVIDER=bedrock) ---
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key

# --- ChromaDB ---
# Options: persistent | http | cloud
CHROMA_CLIENT_TYPE=http                # persistent | http | cloud
# CHROMA_PERSIST_PATH=./chroma_data    # For persistent (not used with http or cloud)
CHROMA_HOST=chromadb                   # For http (use 'chromadb' in Docker, 'localhost' locally)
CHROMA_PORT=8000                       # For http (use 8000 in Docker, 8001 locally)
# CHROMA_TENANT_ID=""
# CHROMA_DATABASE=""
# CHROMA_CLOUD_API_KEY=""
CHROMA_COLLECTION_NAME=sentio_reviews

# --- Retrieval ---
RETRIEVAL_TOP_K=5
RETRIEVAL_THRESHOLD=1.2

# --- Chunking ---
CHUNK_SIZE=500
CHUNK_OVERLAP=100

# --- Ingestion ---
# Set to empty for no limit
INGEST_LIMIT=1000

# --- Logging ---
LOG_LEVEL=INFO
LOG_TO_FILE=true

# Data Directory (optional - defaults to PROJECT_ROOT/data)
# DATA_DIR=/path/to/data  # Override default data directory location
